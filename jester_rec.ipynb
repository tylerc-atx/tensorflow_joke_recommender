{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division, absolute_import, print_function\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tfrec import Recommender\n",
    "import pickle\n",
    "import os\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "joke_ratings = pd.read_csv(\"jester_train.csv\", header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>joke_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>32737.979550</td>\n",
       "      <td>70.710539</td>\n",
       "      <td>1.618454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>18282.777812</td>\n",
       "      <td>46.004394</td>\n",
       "      <td>5.303466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>-10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>17217.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>-2.031000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>34837.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>2.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>47302.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>5.719000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>63978.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              user_id         joke_id          rating\n",
       "count  1000000.000000  1000000.000000  1000000.000000\n",
       "mean     32737.979550       70.710539        1.618454\n",
       "std      18282.777812       46.004394        5.303466\n",
       "min          1.000000        5.000000      -10.000000\n",
       "25%      17217.000000       21.000000       -2.031000\n",
       "50%      34837.000000       69.000000        2.250000\n",
       "75%      47302.000000      112.000000        5.719000\n",
       "max      63978.000000      150.000000       10.000000"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joke_ratings.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000, 3)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joke_ratings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>joke_id</th>\n",
       "      <th>5</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>13</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>...</th>\n",
       "      <th>141</th>\n",
       "      <th>142</th>\n",
       "      <th>143</th>\n",
       "      <th>144</th>\n",
       "      <th>145</th>\n",
       "      <th>146</th>\n",
       "      <th>147</th>\n",
       "      <th>148</th>\n",
       "      <th>149</th>\n",
       "      <th>150</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000</td>\n",
       "      <td>-9.281</td>\n",
       "      <td>-9.281</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-8.719</td>\n",
       "      <td>-9.156</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000</td>\n",
       "      <td>9.938</td>\n",
       "      <td>0.000</td>\n",
       "      <td>9.938</td>\n",
       "      <td>0.406</td>\n",
       "      <td>3.719</td>\n",
       "      <td>9.656</td>\n",
       "      <td>-2.688</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-9.125</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-9.844</td>\n",
       "      <td>-9.844</td>\n",
       "      <td>-7.219</td>\n",
       "      <td>-2.031</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-9.969</td>\n",
       "      <td>-9.875</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-5.812</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000</td>\n",
       "      <td>4.750</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>6.219</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5.406</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 140 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "joke_id    5      7      8      13     15     16     17     18     19     20   \\\n",
       "user_id                                                                         \n",
       "1        0.000 -9.281 -9.281  0.000  0.875  0.000  0.000  0.000 -8.719 -9.156   \n",
       "2        0.000  9.938  0.000  9.938  0.406  3.719  9.656 -2.688  0.000 -9.125   \n",
       "3       -9.844 -9.844 -7.219 -2.031  0.000 -9.969 -9.875  0.000  0.000  0.000   \n",
       "4       -5.812  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "5        0.000  4.750  0.000  0.000  0.000  0.000  6.219  0.000  0.000  5.406   \n",
       "\n",
       "joke_id ...   141  142  143  144  145  146  147  148  149  150  \n",
       "user_id ...                                                     \n",
       "1       ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2       ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3       ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4       ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "5       ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 140 columns]"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joke_matrix = pd.pivot_table(joke_ratings,\n",
    "                             values='rating',\n",
    "                             index='user_id',\n",
    "                             columns='joke_id'\n",
    "                            )\n",
    "joke_matrix.fillna(value=0, inplace=True)\n",
    "\n",
    "joke_matrix.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "jr1 = joke_ratings[joke_ratings['user_id'] < 17000]\n",
    "jr2 = joke_ratings[(joke_ratings['user_id'] < 35000) & (joke_ratings['user_id']>=17500)]\n",
    "jr3 = joke_ratings[(joke_ratings['user_id'] < 47500) & (joke_ratings['user_id']>=35000)]          \n",
    "jr4 = joke_ratings[joke_ratings['user_id'] >=47500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-05-15 15:34:00,194: tfrec.recommender : INFO      : will `fit()` fresh\n",
      "INFO:tfrec.recommender:will `fit()` fresh\n",
      "2017-05-15 15:34:00,847: tfrec.recommender : INFO      : new_num_users: 58127, new_num_items: 142\n",
      "INFO:tfrec.recommender:new_num_users: 58127, new_num_items: 142\n",
      "2017-05-15 15:34:00,848: tfrec.recommender : INFO      : num_users: 58127, num_items: 142\n",
      "INFO:tfrec.recommender:num_users: 58127, num_items: 142\n",
      "2017-05-15 15:34:01,750: tfrec.recommender : INFO      : instantiated a new TensorFlow session\n",
      "INFO:tfrec.recommender:instantiated a new TensorFlow session\n",
      "2017-05-15 15:34:04,058: tfrec.recommender : INFO      : Starting Gradient Descent for 3000 iterations\n",
      "INFO:tfrec.recommender:Starting Gradient Descent for 3000 iterations\n",
      "2017-05-15 15:34:04,198: tfrec.recommender : INFO      : training set RMSE = 5.49710655212\n",
      "INFO:tfrec.recommender:training set RMSE = 5.49710655212\n",
      "2017-05-15 15:34:04,624: tfrec.recommender : INFO      : Finished iteration #1\n",
      "INFO:tfrec.recommender:Finished iteration #1\n",
      "2017-05-15 15:34:04,777: tfrec.recommender : INFO      : training set RMSE = 5.22138643265\n",
      "INFO:tfrec.recommender:training set RMSE = 5.22138643265\n",
      "2017-05-15 15:37:54,116: tfrec.recommender : INFO      : Finished iteration #1001\n",
      "INFO:tfrec.recommender:Finished iteration #1001\n",
      "2017-05-15 15:37:54,195: tfrec.recommender : INFO      : training set RMSE = 1.95162272453\n",
      "INFO:tfrec.recommender:training set RMSE = 1.95162272453\n",
      "2017-05-15 15:41:53,478: tfrec.recommender : INFO      : Finished iteration #2001\n",
      "INFO:tfrec.recommender:Finished iteration #2001\n",
      "2017-05-15 15:41:53,584: tfrec.recommender : INFO      : training set RMSE = 1.11577355862\n",
      "INFO:tfrec.recommender:training set RMSE = 1.11577355862\n",
      "2017-05-15 15:45:42,510: tfrec.recommender : INFO      : Ending Gradient Descent\n",
      "INFO:tfrec.recommender:Ending Gradient Descent\n",
      "2017-05-15 15:45:42,591: tfrec.recommender : INFO      : training set RMSE = 1.00632333755\n",
      "INFO:tfrec.recommender:training set RMSE = 1.00632333755\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Recommender(batch_size=-1, dtype='float32', init_factor_mean=0.17,\n",
       "      init_factor_stddev=0.01, k=50, lambda_biases=0.001,\n",
       "      lambda_factors=0.0001, learning_rate=1e-05, n_iter=3000)"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Recommender(k=50,\n",
    "                    dtype='float32',\n",
    "                    lambda_factors=0.0001,\n",
    "                    lambda_biases=0.001,\n",
    "                    init_factor_mean=0.17, #0.0, \n",
    "                    init_factor_stddev=0.01, # 0.01,\n",
    "                    n_iter=3000,\n",
    "                    learning_rate=1e-05,\n",
    "                    batch_size=-1)\n",
    "\n",
    "X = joke_ratings[['user_id', 'joke_id']].values\n",
    "y = joke_ratings['rating'].values\n",
    "\n",
    "model.fit(X, y, verbose=True, verbose_period=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Jokes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_jokes_for_user(user,\n",
    "                           userid,\n",
    "                           model, \n",
    "                           new=0, \n",
    "                           jokenum=5, \n",
    "                           verbosity=0\n",
    "                          ):\n",
    "    \"\"\"INPUT:\n",
    "            - user_id ('enter arbitrary number if new')\n",
    "            - tfrec Recommender fitted model\n",
    "            - number of jokes to compare\n",
    "            \n",
    "        OUTPUT:\n",
    "            - List of (predicted rating, joke_id) for top\n",
    "              jokes recommended for the user\n",
    "              \n",
    "        OPTIONAL:\n",
    "            - Verbosity greater than 0 will print the\n",
    "              recommended jokes\n",
    "    \"\"\"\n",
    "    \n",
    "    filename = 'jester_jokes.pkl' #No need to add as a parameter\n",
    "    \n",
    "    if new == 0:\n",
    "        userpredict = model.predict(user)\n",
    "    elif new == 1:\n",
    "        userpredict = model.predict_new_user(user)\n",
    "        \n",
    "    jokes_for_user = sorted([(val, model.index_to_item_map_[i])\\\n",
    "                          for i, val in enumerate(userpredict)],\\\n",
    "                          reverse=True\n",
    "                       )\n",
    "    \n",
    "    with open(filename, 'r') as f:\n",
    "        up = pickle.Unpickler(f)\n",
    "        jokelist = up.load()\n",
    "    \n",
    "    if verbosity > 0:\n",
    "        for joke in jokes_for_user[:jokenum]:\n",
    "            score = round(joke[0], 1)\n",
    "            realscore = \"New user\"\n",
    "            print userid\n",
    "            print joke[1]\n",
    "            \n",
    "            if (joke[1] == \"__unknown__\") or (joke[1] == \"__new_entry__\"):\n",
    "                if new == 0:\n",
    "                    realscore = joke[1]\n",
    "                joketext = \"Not found\"\n",
    "            else:\n",
    "                if new == 0:\n",
    "                    realscore = joke_matrix.loc[userid, joke[1]]\n",
    "                joketext = jokelist[joke[1]]\n",
    "                \n",
    "            print \"-\" * 50\n",
    "            print \"Index: {}\\t Score: {}\\t Real Score: {}\".format(\n",
    "                                                                  joke[1],\n",
    "                                                                  score,\n",
    "                                                                  realscore\n",
    "                                                                 )\n",
    "            \n",
    "            print joketext\n",
    "            \n",
    "    return jokes_for_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700\n",
      "18\n",
      "--------------------------------------------------\n",
      "Index: 18\t Score: 7.7\t Real Score: 5.125\n",
      "Q: If a person who speaks three languages is called \"trilingual,\" and a person who speaks two languages is called \"bilingual,\" what do you call a person who only speaks one language?\n",
      "\n",
      "A: American!\n",
      "700\n",
      "69\n",
      "--------------------------------------------------\n",
      "Index: 69\t Score: 4.8\t Real Score: 0.0\n",
      "Employer to applicant: \"In this job we need someone who is responsible.\"\n",
      "\n",
      "Applicant: \"I'm the one you want. On my last job, every time anything went wrong, they said I was responsible.\"\n",
      "700\n",
      "66\n",
      "--------------------------------------------------\n",
      "Index: 66\t Score: 4.0\t Real Score: 0.0\n",
      "Once upon a time, two brooms fell in love and decided to get married. Before the ceremony, the bride broom informed the groom broom that she was expecting a little whiskbroom. The groom broom was aghast!\n",
      "\n",
      "\"How is this possible?\" he asked. \"We've never swept together!\"\n",
      "700\n",
      "__new_entry__\n",
      "--------------------------------------------------\n",
      "Index: __new_entry__\t Score: 3.6\t Real Score: __new_entry__\n",
      "Not found\n",
      "700\n",
      "144\n",
      "--------------------------------------------------\n",
      "Index: 144\t Score: 2.3\t Real Score: 0.0\n",
      "A blonde, brunette, and a red head are all lined up to be shot to death by a firing squad.\n",
      "\n",
      "The brunette shouts, \"Tornado!\" and the riflemen turn around to see the tornado. It isn't there, and the brunette uses that time to escape.\n",
      "\n",
      "The red head yells, \"Lightning!\" and the riflemen again turn to see the disaster, yet there is no disaster and the red head escapes.\n",
      "\n",
      "The blonde yells, \"Fire!\"\n",
      "\n",
      "The riflemen do.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(7.7228003, 18),\n",
       " (4.8356233, 69),\n",
       " (4.0065742, 66),\n",
       " (3.637743, '__new_entry__'),\n",
       " (2.2578909, 144),\n",
       " (1.91643, '__unknown__'),\n",
       " (1.7863848, 29),\n",
       " (1.722373, 16),\n",
       " (1.3911861, 42),\n",
       " (1.3106754, 148),\n",
       " (1.2847807, 60),\n",
       " (1.2172879, 96),\n",
       " (1.0438631, 109),\n",
       " (0.69476438, 7),\n",
       " (0.52396357, 8),\n",
       " (-0.33350694, 119),\n",
       " (-0.63891971, 106),\n",
       " (-2.2273121, 33),\n",
       " (-2.3053966, 15),\n",
       " (-2.7273655, 114),\n",
       " (-3.8159094, 129),\n",
       " (-5.5110168, 99),\n",
       " (-5.6595535, 17)]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_three = X[X[:, 0] == 700]\n",
    "predict_jokes_for_user(user_three, 700, model, verbosity=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18000\n",
      "99\n",
      "--------------------------------------------------\n",
      "Index: 99\t Score: 3.4\t Real Score: 0.0\n",
      "Q: Whats the difference between greeting a queen and greeting the President of the United States?\n",
      "\n",
      "A: You only have to get on one knee to greet the queen.\n",
      "18000\n",
      "29\n",
      "--------------------------------------------------\n",
      "Index: 29\t Score: 3.2\t Real Score: 7.062\n",
      "Q: What's the difference between a lawyer and a plumber? \n",
      "\n",
      "A: A plumber works to unclog the system.\n",
      "18000\n",
      "__unknown__\n",
      "--------------------------------------------------\n",
      "Index: __unknown__\t Score: 3.2\t Real Score: __unknown__\n",
      "Not found\n",
      "18000\n",
      "16\n",
      "--------------------------------------------------\n",
      "Index: 16\t Score: 3.2\t Real Score: 0.0\n",
      "How many men does it take to screw in a light bulb?\n",
      "\n",
      "One. Men will screw anything.\n",
      "18000\n",
      "66\n",
      "--------------------------------------------------\n",
      "Index: 66\t Score: 3.1\t Real Score: 0.0\n",
      "Once upon a time, two brooms fell in love and decided to get married. Before the ceremony, the bride broom informed the groom broom that she was expecting a little whiskbroom. The groom broom was aghast!\n",
      "\n",
      "\"How is this possible?\" he asked. \"We've never swept together!\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(3.3892884, 99),\n",
       " (3.2215571, 29),\n",
       " (3.2038801, '__unknown__'),\n",
       " (3.1751614, 16),\n",
       " (3.1459892, 66),\n",
       " (3.0017977, 18),\n",
       " (2.4766316, 33),\n",
       " (2.3004045, 7),\n",
       " (1.9519881, '__new_entry__'),\n",
       " (1.8357029, 109),\n",
       " (1.8251524, 8),\n",
       " (-1.531932, 60),\n",
       " (-2.5158315, 129)]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = jr2[['user_id', 'joke_id']].values\n",
    "y_test = jr2['rating'].values\n",
    "\n",
    "user_new = X_test[X_test[:, 0] == 18000]\n",
    "predict_jokes_for_user(user_new, 18000, model, verbosity=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_test(model, filename='./test_predictions.csv'):\n",
    "    \n",
    "    joke_test = pd.read_csv(\"jester_test.csv\", header=0)\n",
    "    jt = joke_test.values\n",
    "    \n",
    "    predictions = model.predict(jt)\n",
    "    \n",
    "    joke_test['rating_target'] = predictions\n",
    "\n",
    "    joke_test.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_test(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graphlab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphlab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "joke_ratings2 = pd.read_csv(\"jester_train.csv\", header=0)\n",
    "joke_ratings2['item_id'] = joke_ratings2['joke_id']\n",
    "del joke_ratings2['joke_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf = graphlab.SFrame(joke_ratings2)\n",
    "fr = graphlab.recommender.factorization_recommender\n",
    "\n",
    "m = fr.create(sf,\n",
    "               target='rating',\n",
    "               num_factors=150,\n",
    "               regularization=1e-12,\n",
    "               linear_regularization=1e-12,\n",
    "               nmf=False,\n",
    "               max_iterations=100,\n",
    "               solver='als',\n",
    "               verbose=False\n",
    "              )\n",
    "recs = m.recommend()\n",
    "print recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_graphlab_test(model, filename='./test_predictions.csv'):\n",
    "    \n",
    "    joke_test = pd.read_csv(\"jester_test.csv\", header=0)\n",
    "    joke_test['item_id'] = joke_test['joke_id']\n",
    "    \n",
    "    jt = sf = graphlab.SFrame(joke_test)\n",
    "\n",
    "    predictions = model.predict(jt).to_numpy()\n",
    "    \n",
    "    del joke_test['item_id']\n",
    "    joke_test['rating_target'] = predictions\n",
    "    joke_test.to_csv('./test_predictions_temp.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_graphlab_test(m)\n",
    "%run scoring.py test_predictions.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "joke_test = pd.read_csv(\"jester_test.csv\", header=0)\n",
    "joke_test['item_id'] = joke_test['joke_id']\n",
    "\n",
    "sf_test = graphlab.SFrame(joke_test)\n",
    "sf_train = graphlab.SFrame(joke_ratings2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scoring\n",
    "\n",
    "def scorer(model, train, test):\n",
    "    \"\"\"\n",
    "    For each user, this scoring metric will select the 5% of jokes\n",
    "    predicted to be most highly rated by that user. It then looks\n",
    "    at the actual ratings (in the test data) that the user gave\n",
    "    those jokes. Your score is the average of those ratings.\n",
    "\n",
    "    Use this metric when reporting the score of your joke recommender.\n",
    "    \"\"\"\n",
    "    joke_test = pd.read_csv(\"jester_test.csv\", header=0)\n",
    "    joke_test['item_id'] = joke_test['joke_id']\n",
    "    \n",
    "    jt = sf = graphlab.SFrame(joke_test)\n",
    "\n",
    "    predictions = model.predict(jt).to_numpy()\n",
    "    \n",
    "    del joke_test['item_id']\n",
    "    joke_test['rating_target'] = predictions\n",
    "    joke_test.to_csv('./test_predictions_temp.csv', index=False)\n",
    "    \n",
    "    predictions = pd.read_csv('./test_predictions_temp.csv')\n",
    "    score = scoring.score_top_5_percent(predictions)\n",
    "    \n",
    "    \n",
    "    return {'average rankings': score}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'average rankings': 2.279299794497302}"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scorer(m, 'tain', 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mycluster' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-254-82b51bac1d39>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m           \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m           \u001b[0mevaluator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscorer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m           \u001b[0menvironment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmycluster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m          )\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mycluster' is not defined"
     ]
    }
   ],
   "source": [
    "gs = graphlab.toolkits.model_parameter_search.grid_search\n",
    "\n",
    "params = dict([('target', ['rating']),\n",
    "               ('num_factors', [50, 8, 25, 100]),\n",
    "               ('regularization', [0.01, 0.1, 1]),\n",
    "               ('linear_regularization', [0.001, 0.1, 1]),\n",
    "               ('nmf', [False, True]),\n",
    "               ('max_iterations', [500, 1000, 3000]),\n",
    "               ('solver', ['sgd', 'als']),\n",
    "               ('sgd_step_size', [1e-05, 0.0001, 0.001, 0.1, 1]),\n",
    "               ('verbose', [False]),\n",
    "              ])\n",
    "\n",
    "job = gs.create((sf_train, sf_test),\n",
    "          graphlab.recommender.factorization_recommender.create,\n",
    "          params,\n",
    "          evaluator=scorer,\n",
    "          environment=mycluster\n",
    "         )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-248-7f2aeade60b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/tyler/anaconda/lib/python2.7/site-packages/graphlab/toolkits/model_parameter_search/_model_parameter_search.pyc\u001b[0m in \u001b[0;36mget_results\u001b[0;34m(self, wait)\u001b[0m\n\u001b[1;32m    739\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    740\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 741\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    742\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjobs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/tyler/anaconda/lib/python2.7/site-packages/graphlab/toolkits/model_parameter_search/_model_parameter_search.pyc\u001b[0m in \u001b[0;36m_wait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 712\u001b[0;31m             \u001b[0m_time\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    713\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "job.get_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] graphlab.connect.aws._ec2: Launching an m3.xlarge instance in the us-west-2c availability zone, with id: i-04a89355b0b32fa54. You will be responsible for the cost of this instance.\n",
      "INFO:graphlab.connect.aws._ec2:Launching an m3.xlarge instance in the us-west-2c availability zone, with id: i-04a89355b0b32fa54. You will be responsible for the cost of this instance.\n",
      "[INFO] graphlab.deploy._executionenvironment: Waiting for i-04a89355b0b32fa54 to start up.\n",
      "INFO:graphlab.deploy._executionenvironment:Waiting for i-04a89355b0b32fa54 to start up.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Unable to start host(s). Please terminate manually from the AWS console.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-253-def9b5611736>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmycluster\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraphlab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeploy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mec2_cluster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ec2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m's3://tylerandkeisukesbucket/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mmycluster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/tyler/anaconda/lib/python2.7/site-packages/graphlab/deploy/ec2_cluster.pyc\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(name, s3_path, ec2_config, num_hosts, additional_packages, idle_shutdown_timeout)\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0mcluster\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEc2Cluster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mec2_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms3_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_hosts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madditional_packages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midle_shutdown_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0mcluster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcluster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/tyler/anaconda/lib/python2.7/site-packages/graphlab/deploy/ec2_cluster.pyc\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    231\u001b[0m                                                                        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_hosts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m                                                                        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madditional_packages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m                                                                        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midle_shutdown_timeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m                                                                        )\n\u001b[1;32m    235\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/tyler/anaconda/lib/python2.7/site-packages/graphlab/deploy/_executionenvironment.pyc\u001b[0m in \u001b[0;36m_start_commander_host\u001b[0;34m(env_name, config, s3_folder_path, num_hosts, additional_packages, idle_shutdown_timeout)\u001b[0m\n\u001b[1;32m    370\u001b[0m             \u001b[0m_wait_for_host_to_start_up\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m             raise RuntimeError('Unable to start host(s). Please terminate '\n\u001b[0m\u001b[1;32m    373\u001b[0m                                'manually from the AWS console.')\n\u001b[1;32m    374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Unable to start host(s). Please terminate manually from the AWS console."
     ]
    }
   ],
   "source": [
    "config = graphlab.deploy.Ec2Config(aws_access_key_id='AKIAJNOKRDAJBCJPMEDQ',\n",
    "                         aws_secret_access_key='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'\n",
    "                         )\n",
    "\n",
    "\n",
    "mycluster = graphlab.deploy.ec2_cluster.create('ec2', 's3://tylerandkeisukesbucket/', config)\n",
    "\n",
    "mycluster.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "ename": "NoAuthHandlerFound",
     "evalue": "No handler was ready to authenticate. 1 handlers were checked. ['HmacAuthV1Handler'] Check your credentials",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNoAuthHandlerFound\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-255-b000fec5d919>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgraphlab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeploy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mec2_cluster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m's3://tylerandkeisukesbucket/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/tyler/anaconda/lib/python2.7/site-packages/graphlab/deploy/ec2_cluster.pyc\u001b[0m in \u001b[0;36mload\u001b[0;34m(s3_path)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0mgraphlab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeploy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mec2_cluster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     '''\n\u001b[0;32m--> 111\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_artifact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms3_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/state'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m     \u001b[0m_default_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/tyler/anaconda/lib/python2.7/site-packages/graphlab/deploy/_artifact.pyc\u001b[0m in \u001b[0;36mload_artifact\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \"\"\"\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0munpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgl_pickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGLUnpickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m# Get the version\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/tyler/anaconda/lib/python2.7/site-packages/graphlab/_gl_pickle.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename)\u001b[0m\n\u001b[1;32m    446\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtmp_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_temp_filename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m             \u001b[0;31m# GLC 1.3 uses zipfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0m_file_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_valid_s3_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m                 _file_util.download_from_s3(filename, self.tmp_file, \\\n\u001b[1;32m    450\u001b[0m                         aws_credentials = _get_aws_credentials(), is_dir=False, silent=True)\n",
      "\u001b[0;32m/Users/tyler/anaconda/lib/python2.7/site-packages/graphlab/util/file_util.pyc\u001b[0m in \u001b[0;36m_is_valid_s3_key\u001b[0;34m(s3_path, aws_credentials)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_is_valid_s3_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms3_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maws_credentials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m     \u001b[0mkey_prefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_s3_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms3_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mkey_prefix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/tyler/anaconda/lib/python2.7/site-packages/graphlab/util/file_util.pyc\u001b[0m in \u001b[0;36m_get_s3_key\u001b[0;34m(s3_path, aws_credentials)\u001b[0m\n\u001b[1;32m    710\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_get_s3_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms3_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maws_credentials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m     \u001b[0;34m'''Given S3 path, get the key object that represents the path'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 712\u001b[0;31m     \u001b[0mconn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mboto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect_s3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0maws_credentials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    713\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0mbucket_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_s3_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms3_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m     \u001b[0mbucket\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_bucket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbucket_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/tyler/anaconda/lib/python2.7/site-packages/boto/__init__.pyc\u001b[0m in \u001b[0;36mconnect_s3\u001b[0;34m(aws_access_key_id, aws_secret_access_key, **kwargs)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \"\"\"\n\u001b[1;32m    140\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mboto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ms3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mS3Connection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mS3Connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maws_access_key_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maws_secret_access_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/tyler/anaconda/lib/python2.7/site-packages/boto/s3/connection.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, aws_access_key_id, aws_secret_access_key, is_secure, port, proxy, proxy_port, proxy_user, proxy_pass, host, debug, https_connection_factory, calling_format, path, provider, bucket_class, security_token, suppress_consec_slashes, anon, validate_certs, profile_name)\u001b[0m\n\u001b[1;32m    188\u001b[0m                 \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprovider\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprovider\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msecurity_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msecurity_token\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m                 \u001b[0msuppress_consec_slashes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msuppress_consec_slashes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m                 validate_certs=validate_certs, profile_name=profile_name)\n\u001b[0m\u001b[1;32m    191\u001b[0m         \u001b[0;31m# We need to delay until after the call to ``super`` before checking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0;31m# to see if SigV4 is in use.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/tyler/anaconda/lib/python2.7/site-packages/boto/connection.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, host, aws_access_key_id, aws_secret_access_key, is_secure, port, proxy, proxy_port, proxy_user, proxy_pass, debug, https_connection_factory, path, provider, security_token, suppress_consec_slashes, validate_certs, profile_name)\u001b[0m\n\u001b[1;32m    567\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_last_rs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m         self._auth_handler = auth.get_auth_handler(\n\u001b[0;32m--> 569\u001b[0;31m             host, config, self.provider, self._required_auth_capability())\n\u001b[0m\u001b[1;32m    570\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'AuthServiceName'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauth_service_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAuthServiceName\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/tyler/anaconda/lib/python2.7/site-packages/boto/auth.pyc\u001b[0m in \u001b[0;36mget_auth_handler\u001b[0;34m(host, config, provider, requested_capability)\u001b[0m\n\u001b[1;32m    939\u001b[0m             \u001b[0;34m'No handler was ready to authenticate. %d handlers were checked.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    940\u001b[0m             \u001b[0;34m' %s '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 941\u001b[0;31m             'Check your credentials' % (len(names), str(names)))\n\u001b[0m\u001b[1;32m    942\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    943\u001b[0m     \u001b[0;31m# We select the last ready auth handler that was loaded, to allow users to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNoAuthHandlerFound\u001b[0m: No handler was ready to authenticate. 1 handlers were checked. ['HmacAuthV1Handler'] Check your credentials"
     ]
    }
   ],
   "source": [
    "graphlab.deploy.ec2_cluster.load('s3://tylerandkeisukesbucket/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
